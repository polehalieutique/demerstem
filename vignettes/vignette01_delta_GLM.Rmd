---
title: "vignette01_delta_GLM"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{vignette01_delta_GLM}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, warning = FALSE}
library(demerstem)
```

This first vignette aims to help *demerstem* package users to understand and use the different functions used for the AI calculation process, based on the delta-GLM method.
Cette première vignette doit aider les utilisateurs du package *demerstem* à comprendre et utiliser les différentes fonctions utilisées dans le processus de calcul d'IA (Indice d'Abondance) basé sur la méthode delta-GLM.

As it aims to be used on a broad scale, this vignette will be written in english for international users, but also in french as most of Demerstem program participants are french-speakers.
Comme il doit être utiliser à une large échelle, cette vignette sera écrite en anglais pour les utilisateurs internationaux, mais aussi en français comme une majeur partie des participants au projet Demerstem sont francophones.


## 1) Data manipulation / Manipulation des données

To illustrate this vignette, I'll be using data from scientific campaign in Guinea, which are also available in the package.
Pour illustrer cette vignette, je vais utiliser un jeu de donnée de campagne scientifique en Guinée, qui est également disponible dans le package.

```{r}
data(tableau_sc)
```

The *demerstem* package needs some specifics data table formats as inputs for several functions. For the GLM modeling, you need a table with catch data, fishing effort (several columns are possible), species designation, as well as the parameters needed to identify one single fishing operation (date, position, vessel, etc...). Check your data, filter, transform if necessary. Be sure that the table is already aggregated.
Le package *demerstem* nécessite une certaine forme de tableau en entré pour plusieurs fonctions. Pour la modélisation GLM, il faut un tableau avec les données de captures, l'effort (possiblement plusieurs colonnes), la désignation de l'espèce s'il y en a plusieurs ainsi que les paramètres nécessaires à l'identification d'une opération de pêche (date, position, bateau, etc...). Vérifiez vos données, filtrez, transformez si nécessaire. Veillez à ce que le tableau soit déjà aggregé.


```{r}
tableau_sc <- tableau_sc%>%mutate(code_campagne2=case_when(
  code_campagne2=='GLC'~ "GL",
  TRUE ~ as.character(code_campagne2)
))
tableau_sc <- tableau_sc %>% filter(code_campagne2 %in% c("GL", "AT", "AN"))
```



You may also need to do the stratification of the parameters you will test in your GLMs, as the parameters will be converted as factor later on.
Il vous faudra aussi stratifier vos paramètres testés dans les GLMs, puisqu'ils vont etre converti en facteur par la suite.


```{r}
tableau_sc <- tableau_sc %>% mutate(strate = case_when(
  profond_deb <= 5 ~ "0-5m",
  profond_deb > 5 & profond_deb <=10 ~ "5-10m",
  profond_deb > 10 & profond_deb <=25 ~ "10-25m",
  profond_deb > 25 & profond_deb <= 50 ~ "25-50m",
  profond_deb > 50 & profond_deb <= 100 ~ "50-100m",
  profond_deb > 100 & profond_deb <= 250 ~ "100-250m",
  profond_deb > 250 ~ ">250m"))
```



## 2) GLM modeling and AI calculation / Modélisation GLM et calcul des IA

Your table is now ready. You'll be able to run the 2 GLM modeling functions: *model_ai_plus* and *model_pres_abs*. For this purpose, you'll define the parameters of the functions.
Votre table est à présent prête. Vous puvez faire tourner les 2 fonctions de modélisation des GLM : *model_ai_plus* et *model_pres_abs*. Pour cela, vous devez d'abord définir les paramètres de ces fonctions.

```{r}
# The parameters / Les paramètres
esp <- "PSEUDOTOLITHUS ELONGATUS"
list_param=c("annee", "saison", "strate", "code_campagne2") 
effort="auto"
title="SC"
espece_id ='nom_taxonomique' #exact name of the column naming the species/nom exact de la colonne désignant l'espèce
var_eff_list= c("surface_chalutee") #list of the possible effort values/liste des possibles colonnes effort
catch_col='total_capture'
limit=0.00001
parametres = list_param
```

The *interactions* parameter should be defined as "N" in the first time. If, after the selection process, interactions are kept in the formula, change the *interactions* parameters as "Y", so the GLM modelling function will return the interactions estimates.
Le paramètre *interactions* devrait être défini comme "N" pour le premier test. Si, à la fin du processus de sélection, des interactions sont conservées dans la formule, définissez ce paramètre sur "Y". La fonction de modélisation du GLM vous retournera les valeurs estimées des interactions.


```{r}
#glm_pres <- model_pres_abs(tableau_sc, esp, effort, title, list_param, var_eff_list, espece_id, catch_col, interactions = FALSE, limit, formula_select = "auto")

#glm_ab <- model_ai_plus(tableau_sc, esp, effort, title, list_param, var_eff_list, espece_id, catch_col, interactions = FALSE, limit, formula_select = "log(i_ab+0.0001) ~ strate + annee + saison")
```

For the first run, define *formula_select* as "auto". The function will select automatically, based on a stepAIC process, the formula with the smallest AIC value. Once you have defined the formula with which you want to keep working, assigned it to *formula_select* (see model_ai_plus above).
Lors du premier lancement, définissez *formula_select* sur "auto". La fonction sélectionnera par un processus de stepAIC la formule avec la plus faible valeur d'AIC. Une fois que vous avez défini la formule avec laquelle vous souhaitez travailler, attribuer à *formula_select* votre formule (cf model_ai_plus au dessus).



```{r}
#title <- "Scientific campaign BOBO GIN"

#table_annee_final_SC <- delta_glm(glm_pres, glm_ab, title, type = "SC")
```

The *delta_glm* function realise the pairing between the 2 GLMs. The *type* argument is used later on to define which type of data has been used for this AI series. 
La fonction *delta_glm* va réaliser le couplage entre les 2 GLMs. L'argument *type* sera utiliser plus tard pour définir le type de données utilisées pour le calcul de cette série d'IA.



